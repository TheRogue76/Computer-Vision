{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6ft61e8Fs8mK"
   },
   "source": [
    "# Dataset preparation\n",
    "includes cutting, foldering and separating test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Start: 2020-07-23 17:52:18.205342\n",
      "'CV-Project Phase 1.pdf'   Form_A5.pdf         Main5_Dataset.py\r\n",
      " \u001b[0m\u001b[01;34mdataset\u001b[0m/                  Keras_Alphabet.py   model_no.h5\r\n",
      " Dataset.ipynb             Keras_Intro.ipynb   phaseOne.py\r\n",
      " Dataset.py                Keras_Numbers.py    Test.py\r\n",
      " \u001b[01;34mexamples\u001b[0m/                 Main4_ARUCO.py      Util_Dataset.py\r\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import datetime\n",
    "print(f'Start: {datetime.datetime.now()}')\n",
    "%pwd\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rW8boC-hs8mL",
    "outputId": "25c1013d-2923-4771-fa80-6757e61c1d99",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "from cv2 import aruco\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def ensure_dir(file_path):\n",
    "    \"\"\"ensure given path exists\n",
    "    crates if does not\"\"\"\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def flatten_photo(dict_aruco, width, height, image_path):\n",
    "    \"\"\"flatten photo using aruco dictionary to given size\n",
    "    dict_aruco must follow as \n",
    "    {\n",
    "        topleft  : 0\n",
    "        topright : 1\n",
    "        botright : 2\n",
    "        botleft  : 3\n",
    "    }\n",
    "\n",
    "    Args:\n",
    "        dict_aruco (dict): arco dictonary\n",
    "        width (int): width of warped picture\n",
    "        height (int): height of warped picture\n",
    "        image_path (string): image to read\n",
    "\n",
    "    Returns:\n",
    "        cv.image: warped image\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = cv2.imread(image_path)\n",
    "        # ARUCO finding process\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        aruco_dict = aruco.Dictionary_get(aruco.DICT_6X6_250)\n",
    "        parameters = aruco.DetectorParameters_create()\n",
    "        corners, ids, rejected_img_points = aruco.detectMarkers(\n",
    "            gray, aruco_dict, parameters=parameters)\n",
    "        source_points = np.zeros((4, 2), dtype=np.dtype('int32'))\n",
    "        if len(ids) != 4:\n",
    "            print(\"Less than 4 aruco\", image_path)\n",
    "            return None\n",
    "        #Fill source_points from corner of aruco\n",
    "        for i in range(4):\n",
    "            aruco_id = ids[i][0]\n",
    "            corn = dict_aruco[aruco_id]\n",
    "            x = corners[i][0][corn][0]\n",
    "            y = corners[i][0][corn][1]\n",
    "          \n",
    "            source_points[corn][0] = x\n",
    "            source_points[corn][1] = y\n",
    "            pass\n",
    "        dest_points = np.array([\n",
    "          (0, 0),           #Top left\n",
    "          (width, 0),       #Top Right\n",
    "          (width, height),  #Bot Right\n",
    "          (0, height), ])   #Bot Left\n",
    "        #calculate Homography and warp image\n",
    "        H, mask = cv2.findHomography(source_points, dest_points, cv2.RANSAC, 4.0)\n",
    "        warped = cv2.warpPerspective(img, H, (width, height))\n",
    "    except:\n",
    "        print(f\"ERROR: path:{image_path}\")\n",
    "        return None\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "dict_aruco = {\n",
    "    30: 0,\n",
    "    31: 1,\n",
    "    33: 2,\n",
    "    32: 3,\n",
    "}\n",
    "\n",
    "size = 32  # size of each cell (pixel)\n",
    "with_no = 14  # number of cells in row/width\n",
    "height_no = 21  # number of cells in column/height\n",
    "test_ration = 0.05 # ratio of items for testing\n",
    "\n",
    "#directory to read and save images\n",
    "raw_dir = \"dataset/raw/\"\n",
    "processed_dir = \"dataset/processed/\"\n",
    "test_dir = \"dataset/test/\"\n",
    "\n",
    "list_items_1 = [\n",
    "    [\"no_0\", 10, \"۰\"],\n",
    "    [\"no_1\", 10, \"۱\"],\n",
    "    [\"al_al\", 14, \"ا\"],\n",
    "    [\"al_be\", 14, \"ب\"],\n",
    "    [\"al_pe\", 14, \"پ\"],\n",
    "    [\"al_te\", 14, \"ت\"],\n",
    "    [\"al_sn\", 14, \"ث\"],\n",
    "    [\"al_jm\", 14, \"ج\"],\n",
    "    [\"al_ch\", 14, \"چ\"],\n",
    "    [\"al_hh\", 14, \"ح\"],\n",
    "    [\"al_kh\", 14, \"خ\"],\n",
    "    [\"al_dl\", 14, \"د\"],\n",
    "    [\"al_zl\", 14, \"ذ\"],\n",
    "    [\"al_rr\", 14, \"ر\"],\n",
    "    [\"al_zz\", 14, \"ز\"],\n",
    "    [\"al_jz\", 14, \"ژ\"],\n",
    "    [\"al_sn\", 14, \"س\"],\n",
    "    [\"al_shn\", 14, \"ش\"],\n",
    "    [\"al_sd\", 14, \"ص\"],\n",
    "    [\"no_2\", 10, \"۲\"],\n",
    "    [\"no_3\", 10, \"۳\"]]\n",
    "\n",
    "list_items_2 = [\n",
    "    [\"no_4\", 10, \"۴\"],\n",
    "    [\"no_5\", 10, \"۵\"],\n",
    "    [\"al_zd\", 14, \"ض\"],\n",
    "    [\"al_ta\", 14, \"ط\"],\n",
    "    [\"al_za\", 14, \"ظ\"],\n",
    "    [\"al_ay\", 14, \"ع\"],\n",
    "    [\"al_ghy\", 14, \"غ\"],\n",
    "    [\"al_fe\", 14, \"ف\"],\n",
    "    [\"al_gh\", 14, \"ق\"],\n",
    "    [\"al_kf\", 14, \"ک\"],\n",
    "    [\"al_gf\", 14, \"گ\"],\n",
    "    [\"al_lm\", 14, \"ل\"],\n",
    "    [\"al_mm\", 14, \"م\"],\n",
    "    [\"al_nn\", 14, \"ن\"],\n",
    "    [\"al_vv\", 14, \"و\"],\n",
    "    [\"al_he\", 14, \"ه\"],\n",
    "    [\"al_ye\", 14, \"ی\"],\n",
    "    [\"no_6\", 14, \"۶\"],\n",
    "    [\"no_7\", 14, \"۷\"],\n",
    "    [\"no_8\", 10, \"۸\"],\n",
    "    [\"no_9\", 10, \"۹\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iuE-bsDMs8mf",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1:25\n",
      "Class 2:22\n"
     ]
    }
   ],
   "source": [
    "fnames_1 = glob.glob(f\"{raw_dir}/*_1*.jpg\")\n",
    "fnames_2 = glob.glob(f\"{raw_dir}/*_2*.jpg\")\n",
    "fnames_1.sort()\n",
    "fnames_2.sort()\n",
    "\n",
    "print(f\"Class 1:{len(fnames_1)}\")\n",
    "print(f\"Class 2:{len(fnames_2)}\")\n",
    "fs = [fnames_1, fnames_2]\n",
    "ls = [list_items_1, list_items_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dxwABYWas8mh",
    "outputId": "9cd11bb4-fd17-4849-996b-4c160231d40f",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image Read: 100%|██████████████████████████████████████████████████████████████████████| 25/25 [00:02<00:00,  9.11it/s]\n",
      "Image Slice: 25it [00:00, ?it/s]\n",
      "Image Read: 100%|██████████████████████████████████████████████████████████████████████| 22/22 [00:02<00:00,  9.61it/s]\n",
      "Image Slice: 22it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read  25 pictures\n",
      "===========END OF FOLDER==============\n",
      "for ۰ got 250 blocks\n",
      "for ۱ got 250 blocks\n",
      "for ا got 350 blocks\n",
      "for ب got 350 blocks\n",
      "for پ got 350 blocks\n",
      "for ت got 350 blocks\n",
      "for ث got 350 blocks\n",
      "for ج got 350 blocks\n",
      "for چ got 350 blocks\n",
      "for ح got 350 blocks\n",
      "for خ got 350 blocks\n",
      "for د got 350 blocks\n",
      "for ذ got 350 blocks\n",
      "for ر got 350 blocks\n",
      "for ز got 350 blocks\n",
      "for ژ got 350 blocks\n",
      "for س got 350 blocks\n",
      "for ش got 350 blocks\n",
      "for ص got 350 blocks\n",
      "for ۲ got 250 blocks\n",
      "for ۳ got 250 blocks\n",
      "read  22 pictures\n",
      "===========END OF FOLDER==============\n",
      "for ۴ got 220 blocks\n",
      "for ۵ got 220 blocks\n",
      "for ض got 308 blocks\n",
      "for ط got 308 blocks\n",
      "for ظ got 308 blocks\n",
      "for ع got 308 blocks\n",
      "for غ got 308 blocks\n",
      "for ف got 308 blocks\n",
      "for ق got 308 blocks\n",
      "for ک got 308 blocks\n",
      "for گ got 308 blocks\n",
      "for ل got 308 blocks\n",
      "for م got 308 blocks\n",
      "for ن got 308 blocks\n",
      "for و got 308 blocks\n",
      "for ه got 308 blocks\n",
      "for ی got 308 blocks\n",
      "for ۶ got 308 blocks\n",
      "for ۷ got 308 blocks\n",
      "for ۸ got 220 blocks\n",
      "for ۹ got 220 blocks\n"
     ]
    }
   ],
   "source": [
    "for fnames, list_items in zip(fs, ls):\n",
    "    print(\"===========BEGIN READING CLASS==============\")\n",
    "    class_pic = np.zeros((len(fnames)),dtype=object) #array to hold all pictures in memory (warped)\n",
    "    pic_names = np.zeros((len(fnames)),dtype=object) #array to hold name of all pictures in memory\n",
    "    index = -1\n",
    "    for image_path in tqdm(fnames, desc=\"Image Read\"):\n",
    "        index = index + 1\n",
    "         \n",
    "        f_name = image_path.split(os.path.sep)[-1].split('.')[0]\n",
    "        J_warped = flatten_photo(dict_aruco, size*with_no, size*height_no, image_path)\n",
    "        class_pic[index] = J_warped\n",
    "        pic_names[index] = f_name\n",
    "        if J_warped is None:\n",
    "            #skip if any error occurred\n",
    "            print(f\"Skipped {image_path}\")\n",
    "            continue\n",
    "    #each row holds 1 type of block form all pictures\n",
    "    #e.g.  array_items[4] holds pictures and names for blocks of \"ب\"/\"ط\"\n",
    "    array_items = np.zeros((len(list_items)),dtype=object)\n",
    "    #initialze with empty list\n",
    "    for it in range(len(list_items)):\n",
    "        array_items[it] = []\n",
    "    \n",
    "    #slice picture and populate array_items\n",
    "    for pic, name in tqdm(zip(class_pic,pic_names),desc=\"Image Slice\"):\n",
    "        #skip if a picture did not load\n",
    "        if pic is None:\n",
    "            continue\n",
    "        for row in range(len(list_items)):\n",
    "            #each row, represents a row in picture: ب، پ ،ت...\n",
    "            blocks_per_row = list_items[row][1]\n",
    "            y0 = int(row * size)\n",
    "            y1 = int(y0 + size)\n",
    "            y0 = y0+2\n",
    "            y1 = y1-2\n",
    "            for col in range(blocks_per_row):\n",
    "                #row 0,1 and 19,20 hold 10 items instead of 14\n",
    "                #offset is 2 for these rows\n",
    "                offs =  int(7 - blocks_per_row/2)\n",
    "                \n",
    "                x0 = int((offs + col) * size) \n",
    "                x1 = int(x0 + size)\n",
    "                x0 = x0+2\n",
    "                x1 = x1-2\n",
    "                #result block is 28x28 pixels\n",
    "                block = pic[y0:y1, x0:x1]\n",
    "                #append block in appropriate row of array_items\n",
    "                #add both picture and name\n",
    "                array_items[row].append((block,name))\n",
    "    print(\"===========END OF READING/START SAVING==============\")\n",
    "    for item in range(len(list_items)):\n",
    "        print(f\"for {list_items[item][2]} got {len(array_items[item])} blocks\" )\n",
    "        #Seperate into train and test data\n",
    "        train_input, valid_input = train_test_split(array_items[item],\n",
    "                                                    test_size=test_ration, random_state=103)\n",
    "        #Save train data\n",
    "        save_dir = f\"{processed_dir}{list_items[item][0]}__/\"\n",
    "        ensure_dir(save_dir)\n",
    "        for i in range(len(train_input)):\n",
    "            cv2.imwrite(f\"{save_dir}{train_input[i][1]}_{i}.jpg\", train_input[i][0])\n",
    "        \n",
    "        #Save test data\n",
    "        save_dir = f\"{test_dir}{list_items[item][0]}__/\"\n",
    "        ensure_dir(save_dir)\n",
    "        for i in range(len(valid_input)):\n",
    "            cv2.imwrite(f\"{save_dir}{valid_input[i][1]}_{i}.jpg\", valid_input[i][0])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Keras_Intro.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}